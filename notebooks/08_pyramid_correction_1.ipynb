{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# üèõÔ∏è Pyramid Perspective Correction - Teotihuacan\n",
    "\n",
    "This notebook transforms aerial pyramid images to create a frontal view perspective using OpenCV perspective correction.\n",
    "\n",
    "**Created for Google Colab** üì±\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_packages"
   },
   "outputs": [],
   "source": [
    "# Install required packages (if not already installed)\n",
    "!pip install opencv-python matplotlib numpy pillow\n",
    "\n",
    "# Import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import files\n",
    "import io\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ All packages installed and imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_image"
   },
   "outputs": [],
   "source": [
    "def upload_image():\n",
    "    \"\"\"\n",
    "    Upload an image file in Google Colab\n",
    "    \"\"\"\n",
    "    print(\"üì∏ Please upload your Teotihuacan pyramid image:\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Get the uploaded filename\n",
    "    filename = list(uploaded.keys())[0]\n",
    "    print(f\"‚úÖ Uploaded: {filename}\")\n",
    "    \n",
    "    return filename\n",
    "\n",
    "# Upload your image\n",
    "image_filename = upload_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "preview_image"
   },
   "outputs": [],
   "source": [
    "# Load and display the uploaded image\n",
    "img = cv2.imread(image_filename)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"üì∑ Original Teotihuacan Pyramid Image\", fontsize=16, pad=20)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìê Image dimensions: {img_rgb.shape[1]} x {img_rgb.shape[0]} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "interactive_selection"
   },
   "outputs": [],
   "source": [
    "def interactive_point_selection(image_path):\n",
    "    \"\"\"\n",
    "    Interactive function to help select the correct source points\n",
    "    by clicking on the image.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    points = []\n",
    "    \n",
    "    def onclick(event):\n",
    "        if event.inaxes and len(points) < 4:\n",
    "            points.append([event.xdata, event.ydata])\n",
    "            plt.plot(event.xdata, event.ydata, 'ro', markersize=12)\n",
    "            plt.text(event.xdata + 15, event.ydata - 15, f'{len(points)}', \n",
    "                    fontsize=16, color='red', weight='bold', \n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.9))\n",
    "            plt.draw()\n",
    "            \n",
    "            if len(points) == 4:\n",
    "                # Draw lines connecting the points\n",
    "                x_coords = [p[0] for p in points] + [points[0][0]]\n",
    "                y_coords = [p[1] for p in points] + [points[0][1]]\n",
    "                plt.plot(x_coords, y_coords, 'r-', linewidth=3, alpha=0.7)\n",
    "                plt.draw()\n",
    "                print(\"‚úÖ All 4 points selected!\")\n",
    "                print(\"üìç Points coordinates:\")\n",
    "                for i, point in enumerate(points):\n",
    "                    labels = ['top-left', 'top-right', 'bottom-right', 'bottom-left']\n",
    "                    print(f\"  {i+1}. {labels[i]}: [{point[0]:.1f}, {point[1]:.1f}]\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    ax.imshow(img_rgb)\n",
    "    ax.set_title(\"üéØ Click to select 4 corners of the pyramid base\\n\" +\n",
    "                \"Order: 1Ô∏è‚É£ top-left, 2Ô∏è‚É£ top-right, 3Ô∏è‚É£ bottom-right, 4Ô∏è‚É£ bottom-left\", \n",
    "                fontsize=16, pad=20)\n",
    "    fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "    plt.show()\n",
    "    \n",
    "    return np.float32(points) if len(points) == 4 else None\n",
    "\n",
    "# Run interactive point selection\n",
    "print(\"üìç Select the pyramid base corners by clicking on the image\")\n",
    "print(\"‚ö†Ô∏è Make sure to select in order: top-left ‚Üí top-right ‚Üí bottom-right ‚Üí bottom-left\")\n",
    "selected_points = interactive_point_selection(image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "perspective_correction"
   },
   "outputs": [],
   "source": [
    "def correct_pyramid_perspective(image_path, src_points_custom=None, output_filename=\"corrected_pyramid.jpg\"):\n",
    "    \"\"\"\n",
    "    Transform the perspective of a pyramid image to make it appear as if \n",
    "    the focal plane is parallel to the pyramid's front face.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Could not load image. Check the file path.\")\n",
    "    \n",
    "    # Convert BGR to RGB for matplotlib display\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Get image dimensions\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    # Use custom points if provided, otherwise use default points\n",
    "    if src_points_custom is not None:\n",
    "        src_points = np.float32(src_points_custom)\n",
    "        print(\"üéØ Using custom selected points\")\n",
    "    else:\n",
    "        # Define default source points (you can adjust these if needed)\n",
    "        src_points = np.float32([\n",
    "            [width * 0.35, height * 0.45],  # Top-left of pyramid base\n",
    "            [width * 0.65, height * 0.45],  # Top-right of pyramid base  \n",
    "            [width * 0.75, height * 0.85],  # Bottom-right of pyramid base\n",
    "            [width * 0.25, height * 0.85]   # Bottom-left of pyramid base\n",
    "        ])\n",
    "        print(\"‚ö†Ô∏è Using default points (you may want to adjust these)\")\n",
    "    \n",
    "    # Define destination points (rectangular perspective)\n",
    "    margin = 100\n",
    "    dst_points = np.float32([\n",
    "        [margin, margin],                    # Top-left\n",
    "        [width - margin, margin],            # Top-right\n",
    "        [width - margin, height - margin],   # Bottom-right\n",
    "        [margin, height - margin]            # Bottom-left\n",
    "    ])\n",
    "    \n",
    "    # Calculate the perspective transformation matrix\n",
    "    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    \n",
    "    # Apply the perspective transformation\n",
    "    corrected_img = cv2.warpPerspective(img_rgb, matrix, (width, height))\n",
    "    \n",
    "    # Save the corrected image\n",
    "    corrected_bgr = cv2.cvtColor(corrected_img, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(output_filename, corrected_bgr)\n",
    "    \n",
    "    return corrected_img, matrix, src_points, dst_points\n",
    "\n",
    "# Apply perspective correction using selected points\n",
    "try:\n",
    "    if selected_points is not None and len(selected_points) == 4:\n",
    "        corrected_img, transformation_matrix, src_pts, dst_pts = correct_pyramid_perspective(\n",
    "            image_filename, \n",
    "            selected_points, \n",
    "            \"corrected_pyramid.jpg\"\n",
    "        )\n",
    "        print(\"‚úÖ Perspective correction applied successfully!\")\n",
    "    else:\n",
    "        print(\"‚ùå No valid points selected. Using default points...\")\n",
    "        corrected_img, transformation_matrix, src_pts, dst_pts = correct_pyramid_perspective(\n",
    "            image_filename, \n",
    "            None, \n",
    "            \"corrected_pyramid.jpg\"\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "display_results"
   },
   "outputs": [],
   "source": [
    "# Display the results side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Original image with source points marked\n",
    "axes[0].imshow(img_rgb)\n",
    "axes[0].plot([src_pts[0][0], src_pts[1][0], src_pts[2][0], src_pts[3][0], src_pts[0][0]], \n",
    "             [src_pts[0][1], src_pts[1][1], src_pts[2][1], src_pts[3][1], src_pts[0][1]], \n",
    "             'r-', linewidth=3, label='Source area', alpha=0.8)\n",
    "axes[0].scatter(src_pts[:, 0], src_pts[:, 1], c='red', s=120, zorder=5, edgecolors='white', linewidth=2)\n",
    "\n",
    "# Add point labels\n",
    "labels = ['1', '2', '3', '4']\n",
    "for i, point in enumerate(src_pts):\n",
    "    axes[0].text(point[0] + 20, point[1] - 20, labels[i], fontsize=16, color='red', \n",
    "                weight='bold', bbox=dict(boxstyle=\"circle,pad=0.3\", facecolor=\"white\", alpha=0.9))\n",
    "\n",
    "axes[0].set_title('üì∑ Original Image with Source Points', fontsize=16, pad=20)\n",
    "axes[0].legend(fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Corrected image with destination points marked\n",
    "axes[1].imshow(corrected_img)\n",
    "axes[1].plot([dst_pts[0][0], dst_pts[1][0], dst_pts[2][0], dst_pts[3][0], dst_pts[0][0]], \n",
    "             [dst_pts[0][1], dst_pts[1][1], dst_pts[2][1], dst_pts[3][1], dst_pts[0][1]], \n",
    "             'g-', linewidth=3, label='Destination area', alpha=0.8)\n",
    "axes[1].scatter(dst_pts[:, 0], dst_pts[:, 1], c='green', s=120, zorder=5, edgecolors='white', linewidth=2)\n",
    "\n",
    "axes[1].set_title('üéØ Perspective Corrected Image', fontsize=16, pad=20)\n",
    "axes[1].legend(fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üéâ Transformation complete!\")\n",
    "print(f\"üìÅ Corrected image saved as: corrected_pyramid.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_image"
   },
   "outputs": [],
   "source": [
    "# Download the corrected image\n",
    "def download_corrected_image():\n",
    "    \"\"\"\n",
    "    Download the corrected image to your local machine\n",
    "    \"\"\"\n",
    "    try:\n",
    "        files.download('corrected_pyramid.jpg')\n",
    "        print(\"‚úÖ Download started! Check your Downloads folder.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Download error: {e}\")\n",
    "\n",
    "# Download the corrected image\n",
    "download_corrected_image()\n",
    "\n",
    "print(\"üíæ Your perspective-corrected pyramid image has been downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fine_tuning"
   },
   "outputs": [],
   "source": [
    "def fine_tune_perspective_correction(image_path, src_points, scale_factor=0.8):\n",
    "    \"\"\"\n",
    "    Fine-tune the perspective correction with additional options\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    # Calculate centered destination rectangle\n",
    "    center_x, center_y = width // 2, height // 2\n",
    "    dst_width = int(width * scale_factor)\n",
    "    dst_height = int(height * scale_factor)\n",
    "    \n",
    "    dst_points = np.float32([\n",
    "        [center_x - dst_width//2, center_y - dst_height//2],   # Top-left\n",
    "        [center_x + dst_width//2, center_y - dst_height//2],   # Top-right\n",
    "        [center_x + dst_width//2, center_y + dst_height//2],   # Bottom-right\n",
    "        [center_x - dst_width//2, center_y + dst_height//2]    # Bottom-left\n",
    "    ])\n",
    "    \n",
    "    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    corrected_img = cv2.warpPerspective(img_rgb, matrix, (width, height))\n",
    "    \n",
    "    return corrected_img, matrix\n",
    "\n",
    "# Fine-tune with different scale factors\n",
    "if selected_points is not None:\n",
    "    scale_factors = [0.6, 0.8, 1.0]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(scale_factors), figsize=(18, 6))\n",
    "    \n",
    "    for i, scale in enumerate(scale_factors):\n",
    "        fine_tuned_img, _ = fine_tune_perspective_correction(image_filename, selected_points, scale)\n",
    "        axes[i].imshow(fine_tuned_img)\n",
    "        axes[i].set_title(f'Scale Factor: {scale}', fontsize=14)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('üîß Fine-Tuned Perspective Corrections', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üéõÔ∏è Try different scale factors to find the best result!\")\n",
    "    print(\"üí° Lower scale factors = more zoomed view, Higher = more of the image visible\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please run the point selection cell first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "instructions"
   },
   "source": [
    "## üìã Usage Instructions\n",
    "\n",
    "### üöÄ **Quick Start Guide:**\n",
    "\n",
    "1. **üì∏ Upload Image** (Cell 2)\n",
    "   - Run Cell 2 and upload your Teotihuacan pyramid image\n",
    "   - Supported formats: JPG, PNG, etc.\n",
    "\n",
    "2. **üëÄ Preview Image** (Cell 3)\n",
    "   - View your uploaded image and check dimensions\n",
    "\n",
    "3. **üéØ Select Points** (Cell 4)\n",
    "   - Click on the image to select 4 corners of the pyramid base\n",
    "   - **Order is critical**: top-left ‚Üí top-right ‚Üí bottom-right ‚Üí bottom-left\n",
    "   - Points should form a quadrilateral around the pyramid base\n",
    "\n",
    "4. **‚öôÔ∏è Apply Correction** (Cell 5)\n",
    "   - Automatically applies perspective correction using your selected points\n",
    "   - Falls back to default coordinates if no points selected\n",
    "\n",
    "5. **üìä View Results** (Cell 6)\n",
    "   - Compare original vs. corrected images side by side\n",
    "   - Red markers show source area, green shows destination\n",
    "\n",
    "6. **üíæ Download** (Cell 7)\n",
    "   - Download the corrected image to your computer\n",
    "\n",
    "7. **üîß Fine-Tune** (Cell 8, Optional)\n",
    "   - Experiment with different scale factors for optimal results\n",
    "\n",
    "---\n",
    "\n",
    "### üí° **Pro Tips:**\n",
    "\n",
    "- **Point Selection**: Choose corners that clearly define the pyramid's base rectangle\n",
    "- **Re-run Flexibility**: You can re-run any cell to try different settings\n",
    "- **Best Results**: Works optimally when pyramid occupies significant image area\n",
    "- **Troubleshooting**: If correction looks distorted, try selecting different points\n",
    "\n",
    "---\n",
    "\n",
    "### üîß **Troubleshooting:**\n",
    "\n",
    "- **Point selection not working?** ‚Üí Ensure you're clicking within the image boundaries\n",
    "- **Distorted results?** ‚Üí Check point selection order (top-left ‚Üí top-right ‚Üí bottom-right ‚Üí bottom-left)\n",
    "- **Severe distortion?** ‚Üí Try adjusting destination rectangle size in the code\n",
    "- **Upload issues?** ‚Üí Verify image format (JPG, PNG) and file size\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **Expected Results:**\n",
    "\n",
    "The perspective correction transforms your aerial pyramid view into a frontal perspective, making it appear as if you're viewing the pyramid straight-on with the focal plane parallel to its front face.\n",
    "\n",
    "**Enjoy your perspective-corrected Teotihuacan pyramid! üèõÔ∏è‚ú®**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}